{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural History Museum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article Keyword Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook by Matthew Crisp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyses three articles on the Natural History Museum website's 'Discover' pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries needed for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests #To read the HTML document from the URL\n",
    "from bs4 import BeautifulSoup as soup #To parse and organise HTML elements\n",
    "import pandas as pd #Data handling and analysis\n",
    "import nltk #Natural Language Processing library\n",
    "\n",
    "# Twitter analysis\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_key = 'an1GH9sCfmvFUdISadGvLjlu6'\n",
    "consumer_secret = 'dFG8dM0zXo4zAyppNMCVJDYXy77AdLefrZSS5KBv79dN5QH9Eb'\n",
    "access_token = '323487158-QcuYrKvm90fW4NlUAjV6PmYnvAg7pkVtqR8Lg4jC'\n",
    "access_token_secret = 'ujVjeCLdV6cpPltOyuLrhnbnoJHQwZywvN6Gcrv0vltvJ'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.user_timeline(screen_name='NHM_London', tweet_mode='extended',count=200) #API limit is 200 per request. \n",
    "len(public_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['time'] = [tweet.created_at for tweet in public_tweets]\n",
    "#tweets['id'] =   [tweet.id for tweet in public_tweets]\n",
    "tweets['tweet'] = [tweet.full_text for tweet in public_tweets]\n",
    "tweets['hashtags'] = [tweet.entities['hashtags'] for tweet in public_tweets]\n",
    "tweets['urls'] = [tweet.entities['urls'] for tweet in public_tweets]\n",
    "tweets['user mentions'] = [tweet.entities['user_mentions'] for tweet in public_tweets]\n",
    "tweets['repying to'] = [tweet.in_reply_to_screen_name for tweet in public_tweets]\n",
    "tweets['retweets'] = [tweet.retweet_count for tweet in public_tweets]\n",
    "tweets['favourites'] = [tweet.favorite_count for tweet in public_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user mentions</th>\n",
       "      <th>repying to</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favourites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-07 07:44:42</td>\n",
       "      <td>Watch a virtual Stegosaurus walk around as Sir...</td>\n",
       "      <td>[{'text': 'HoldTheWorld', 'indices': [149, 162]}]</td>\n",
       "      <td>[{'url': 'https://t.co/udPYQFhJsy', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>53</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-06 16:07:12</td>\n",
       "      <td>It's not just in film plots where dinosaurs ar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/VGOu7RrEqw', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-06 14:01:52</td>\n",
       "      <td>Could mosquitos trapped in amber realistically...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/wo0wmQFv2T', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'Tweetisaurus', 'name': 'Susi...</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-06 10:59:19</td>\n",
       "      <td>RT @NHM_London: Did you know there are thought...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHM_London', 'name': 'Natura...</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-06 10:59:12</td>\n",
       "      <td>Did you know there are thought to be more than...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/V0w8uV4w39', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NHM_London</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-06-06 10:03:13</td>\n",
       "      <td>Films like #JurassicWorld have helped some din...</td>\n",
       "      <td>[{'text': 'JurassicWorld', 'indices': [11, 25]}]</td>\n",
       "      <td>[{'url': 'https://t.co/gfJJQleucI', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'NHMdinolab', 'name': 'NHMdin...</td>\n",
       "      <td>None</td>\n",
       "      <td>47</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-06-06 09:01:02</td>\n",
       "      <td>RT @NHM_London: We're also offering a money-ca...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHM_London', 'name': 'Natura...</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-06-06 09:00:53</td>\n",
       "      <td>We're also offering a money-can't-buy prize to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/0wTWLxfVk3', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NHM_London</td>\n",
       "      <td>41</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-06-06 08:58:42</td>\n",
       "      <td>#JurassicWorld is released in UK cinemas today...</td>\n",
       "      <td>[{'text': 'JurassicWorld', 'indices': [0, 14]}]</td>\n",
       "      <td>[{'url': 'https://t.co/4gSgQ8roKe', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-06-05 15:23:41</td>\n",
       "      <td>This #WorldEnvironmentDay we're celebrating ou...</td>\n",
       "      <td>[{'text': 'WorldEnvironmentDay', 'indices': [5...</td>\n",
       "      <td>[{'url': 'https://t.co/jX9sDQDuoR', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-06-05 15:18:18</td>\n",
       "      <td>RT @BBCR1: Velociraptors? We've got them all w...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'BBCR1', 'name': 'BBC Radio 1...</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-06-05 12:45:54</td>\n",
       "      <td>@Jmg64John Hi - You could try our ID forums (h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/iS3mojHHWU', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'Jmg64John', 'name': 'Johnoor...</td>\n",
       "      <td>Jmg64John</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-06-05 12:45:07</td>\n",
       "      <td>@liverpoollou92 Hi - You could try our ID foru...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/iS3mojHHWU', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'liverpoollou92', 'name': 'El...</td>\n",
       "      <td>liverpoollou92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-06-05 10:33:58</td>\n",
       "      <td>#SciNews: First for the first time, scientists...</td>\n",
       "      <td>[{'text': 'SciNews', 'indices': [0, 8]}]</td>\n",
       "      <td>[{'url': 'https://t.co/UUM4NEmn5Z', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-06-05 08:39:28</td>\n",
       "      <td>RT @NHM_WPY: For #WorldEnvironmentDay we're re...</td>\n",
       "      <td>[{'text': 'WorldEnvironmentDay', 'indices': [1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHM_WPY', 'name': 'Wildlife ...</td>\n",
       "      <td>None</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-06-04 16:08:12</td>\n",
       "      <td>Are we really made of stardust? âœ¨ Planetary sc...</td>\n",
       "      <td>[{'text': 'Space', 'indices': [106, 112]}, {'t...</td>\n",
       "      <td>[{'url': 'https://t.co/h5hIYdBYX4', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-06-04 14:19:46</td>\n",
       "      <td>Ahead of #WorldEnvironmentDay we're sharing a ...</td>\n",
       "      <td>[{'text': 'WorldEnvironmentDay', 'indices': [9...</td>\n",
       "      <td>[{'url': 'https://t.co/6hHnEgbWRD', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'NHM_WPY', 'name': 'Wildlife ...</td>\n",
       "      <td>None</td>\n",
       "      <td>49</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-06-04 10:56:43</td>\n",
       "      <td>#MineralMonday Taking care of the Museum's min...</td>\n",
       "      <td>[{'text': 'MineralMonday', 'indices': [0, 14]}]</td>\n",
       "      <td>[{'url': 'https://t.co/tLFfCveEBI', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-06-03 17:19:03</td>\n",
       "      <td>@Grantjones_ Hi Grant, try our ID forums (http...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/iS3mojHHWU', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'Grantjones_', 'name': 'Grant...</td>\n",
       "      <td>Grantjones_</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-06-03 17:18:47</td>\n",
       "      <td>@yayamartin @bugmanjones Hi Jen, try our ID fo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/iS3mojHHWU', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'yayamartin', 'name': 'Jen', ...</td>\n",
       "      <td>yayamartin</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-06-03 13:56:31</td>\n",
       "      <td>RT @NHM_WPY: Did you know the Jamaican iguana ...</td>\n",
       "      <td>[{'text': 'WPYinsights', 'indices': [89, 101]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHM_WPY', 'name': 'Wildlife ...</td>\n",
       "      <td>None</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-06-02 14:23:37</td>\n",
       "      <td>Itâ€™s #ButterflyAwarenessDay. Did you know that...</td>\n",
       "      <td>[{'text': 'ButterflyAwarenessDay', 'indices': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-06-02 13:15:47</td>\n",
       "      <td>It's #ButterflyAwarenessDay ðŸ¦‹. See if you can ...</td>\n",
       "      <td>[{'text': 'ButterflyAwarenessDay', 'indices': ...</td>\n",
       "      <td>[{'url': 'https://t.co/F0Ogxb7HdU', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-06-01 13:59:24</td>\n",
       "      <td>RT @NHMdinolab: Tyrannosaur dentary in the col...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHMdinolab', 'name': 'NHMdin...</td>\n",
       "      <td>None</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-06-01 11:23:09</td>\n",
       "      <td>From capturing one of the world's most endange...</td>\n",
       "      <td>[{'text': 'WPY53', 'indices': [164, 170]}]</td>\n",
       "      <td>[{'url': 'https://t.co/TOcK4Z8sfV', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'NHM_WPY', 'name': 'Wildlife ...</td>\n",
       "      <td>None</td>\n",
       "      <td>47</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-06-01 09:43:50</td>\n",
       "      <td>RT @OrstedUK: Continuing our celebration of #W...</td>\n",
       "      <td>[{'text': 'WPY53', 'indices': [44, 50]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'OrstedUK', 'name': 'Ã˜rsted U...</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-06-01 08:59:47</td>\n",
       "      <td>RT @NHM_WPY: The 2019 competition opens for en...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHM_WPY', 'name': 'Wildlife ...</td>\n",
       "      <td>None</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-06-01 08:59:38</td>\n",
       "      <td>RT @BryozoanNhm: #FossilFriday The famous Le M...</td>\n",
       "      <td>[{'text': 'FossilFriday', 'indices': [17, 30]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'BryozoanNhm', 'name': 'NHM_B...</td>\n",
       "      <td>None</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-05-31 14:00:45</td>\n",
       "      <td>Dippyâ€™s #Naturenauts is supported by @DellEMC,...</td>\n",
       "      <td>[{'text': 'Naturenauts', 'indices': [8, 20]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'DellEMC', 'name': 'Dell EMC'...</td>\n",
       "      <td>NHM_London</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-05-31 14:00:20</td>\n",
       "      <td>Have you joined #Naturenauts? Our brand-new ap...</td>\n",
       "      <td>[{'text': 'Naturenauts', 'indices': [16, 28]},...</td>\n",
       "      <td>[{'url': 'https://t.co/FTy8uPEkXT', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2018-05-13 13:53:45</td>\n",
       "      <td>This orange butterfly can be found in the Amer...</td>\n",
       "      <td>[{'text': 'SensationalButterflies', 'indices':...</td>\n",
       "      <td>[{'url': 'https://t.co/0fZNHedhc6', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2018-05-13 10:56:41</td>\n",
       "      <td>Human evolution expert Prof @ChrisStringer65 w...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/mPJCXiKEYu', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'ChrisStringer65', 'name': 'C...</td>\n",
       "      <td>NHM_London</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2018-05-13 10:56:15</td>\n",
       "      <td>The Museum's @ChrisStringer65 has studied Nean...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/PRQt86brOz', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'ChrisStringer65', 'name': 'C...</td>\n",
       "      <td>None</td>\n",
       "      <td>99</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2018-05-12 13:51:45</td>\n",
       "      <td>What's the coolest dinosaur? Swot up on your d...</td>\n",
       "      <td>[{'text': 'NHM_Live', 'indices': [74, 83]}]</td>\n",
       "      <td>[{'url': 'https://t.co/uFQTioRh4O', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>28</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2018-05-12 13:36:31</td>\n",
       "      <td>@KenWill93191945 Hi Ken - To help you identify...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/Of82R2ZGRH', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'KenWill93191945', 'name': 'K...</td>\n",
       "      <td>KenWill93191945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2018-05-12 11:26:41</td>\n",
       "      <td>RT @anariesgogil: Nature Live @NHM_London abou...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'anariesgogil', 'name': 'Ana ...</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2018-05-12 11:21:57</td>\n",
       "      <td>RT @NHM_Digitise: Happy Birthday Dippy! While ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHM_Digitise', 'name': 'Digi...</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2018-05-12 10:45:59</td>\n",
       "      <td>RT @NHM_Visiting: We currently have a 15 minut...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHM_Visiting', 'name': 'NHM ...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2018-05-12 10:45:15</td>\n",
       "      <td>Come along to our Family Festival this May hal...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/y1UzQlgtvB', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'Operation_Earth', 'name': 'O...</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2018-05-12 09:03:54</td>\n",
       "      <td>RT @NHM_Visiting: A marine worm moves in with ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHM_Visiting', 'name': 'NHM ...</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2018-05-12 08:56:47</td>\n",
       "      <td>RT @nickcasewell: Here is a really nice short ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'nickcasewell', 'name': 'Dr N...</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2018-05-12 08:56:07</td>\n",
       "      <td>RT @NHM_London: #DippyOnTour is in partnership...</td>\n",
       "      <td>[{'text': 'DippyOnTour', 'indices': [16, 28]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHM_London', 'name': 'Natura...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2018-05-12 08:56:00</td>\n",
       "      <td>RT @NHM_London: Dippy is getting ready for the...</td>\n",
       "      <td>[{'text': 'DippyOnTour', 'indices': [124, 136]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHM_London', 'name': 'Natura...</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2018-05-12 08:55:08</td>\n",
       "      <td>#DippyOnTour is in partnership with @GarfieldW...</td>\n",
       "      <td>[{'text': 'DippyOnTour', 'indices': [0, 12]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'GarfieldWFdn', 'name': 'Garf...</td>\n",
       "      <td>NHM_London</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2018-05-12 08:54:44</td>\n",
       "      <td>Dippy is getting ready for the next stop of hi...</td>\n",
       "      <td>[{'text': 'DippyOnTour', 'indices': [108, 120]}]</td>\n",
       "      <td>[{'url': 'https://t.co/lPE7qQq7Dw', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'BM_AG', 'name': 'Birmingham ...</td>\n",
       "      <td>NHM_London</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2018-05-12 08:54:07</td>\n",
       "      <td>Dippy was revealed to the public #OTD in 1905 ...</td>\n",
       "      <td>[{'text': 'OTD', 'indices': [33, 37]}]</td>\n",
       "      <td>[{'url': 'https://t.co/rk6niJ0MlM', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>90</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2018-05-11 15:52:42</td>\n",
       "      <td>Have you ever seen a cobra spit #Venom in supe...</td>\n",
       "      <td>[{'text': 'Venom', 'indices': [32, 38]}]</td>\n",
       "      <td>[{'url': 'https://t.co/zvSrFuRLvX', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'LSTMnews', 'name': 'LSTM', '...</td>\n",
       "      <td>None</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2018-05-11 14:37:38</td>\n",
       "      <td>RT @Filming_at_NHM: Tune in this Sunday to cat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'Filming_at_NHM', 'name': 'Fi...</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2018-05-11 12:55:50</td>\n",
       "      <td>RT @NHMdinolab: Returning freshly conserved fr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'NHMdinolab', 'name': 'NHMdin...</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2018-05-11 11:03:50</td>\n",
       "      <td>Chytridiomycosis regularly kills frogs, toads,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/1CyeG8IknD', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2018-05-11 10:32:35</td>\n",
       "      <td>Great profile of Justin Schmidt in the Guardia...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/8JdCXmSFr6', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2018-05-11 08:57:59</td>\n",
       "      <td>This weekend is your last chance to come face-...</td>\n",
       "      <td>[{'text': 'Venom', 'indices': [103, 109]}]</td>\n",
       "      <td>[{'url': 'https://t.co/fdgYCipzHQ', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2018-05-11 07:53:55</td>\n",
       "      <td>Life after Gollum: motion capture master Andy ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/PZpdaZ0iw7', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>61</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2018-05-10 11:09:37</td>\n",
       "      <td>Meet the ancient people who rocked the surfer ...</td>\n",
       "      <td>[{'text': 'Neanderthals', 'indices': [154, 167...</td>\n",
       "      <td>[{'url': 'https://t.co/iF7Z4qbuau', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>38</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2018-05-10 09:01:49</td>\n",
       "      <td>Rise and shine with our yoga sessions. Taking ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/am5Fscx6g7', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>43</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2018-05-09 14:34:40</td>\n",
       "      <td>Huge congratulations to Dr Greg Edgecombe, who...</td>\n",
       "      <td>[{'text': 'RSFellows', 'indices': [215, 225]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'royalsociety', 'name': 'The ...</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2018-05-09 13:59:15</td>\n",
       "      <td>Our live butterfly house gives you the chance ...</td>\n",
       "      <td>[{'text': 'SensationalButterflies', 'indices':...</td>\n",
       "      <td>[{'url': 'https://t.co/h5dpDQUt4M', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2018-05-09 12:52:39</td>\n",
       "      <td>RT @flygirlNHM: It's #hedgehogweek - did you k...</td>\n",
       "      <td>[{'text': 'hedgehogweek', 'indices': [21, 34]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'flygirlNHM', 'name': 'Erica ...</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2018-05-09 12:01:28</td>\n",
       "      <td>RT @Shop_at_NHM: Step into the sun wearing a t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/12a9nTlCQ5', 'expanded_...</td>\n",
       "      <td>[{'screen_name': 'Shop_at_NHM', 'name': 'Shop ...</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2018-05-09 11:23:44</td>\n",
       "      <td>Monarch butterflies migrate thousands of miles...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/IDFQIPCAFj', 'expanded_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time                                              tweet  \\\n",
       "0   2018-06-07 07:44:42  Watch a virtual Stegosaurus walk around as Sir...   \n",
       "1   2018-06-06 16:07:12  It's not just in film plots where dinosaurs ar...   \n",
       "2   2018-06-06 14:01:52  Could mosquitos trapped in amber realistically...   \n",
       "3   2018-06-06 10:59:19  RT @NHM_London: Did you know there are thought...   \n",
       "4   2018-06-06 10:59:12  Did you know there are thought to be more than...   \n",
       "5   2018-06-06 10:03:13  Films like #JurassicWorld have helped some din...   \n",
       "6   2018-06-06 09:01:02  RT @NHM_London: We're also offering a money-ca...   \n",
       "7   2018-06-06 09:00:53  We're also offering a money-can't-buy prize to...   \n",
       "8   2018-06-06 08:58:42  #JurassicWorld is released in UK cinemas today...   \n",
       "9   2018-06-05 15:23:41  This #WorldEnvironmentDay we're celebrating ou...   \n",
       "10  2018-06-05 15:18:18  RT @BBCR1: Velociraptors? We've got them all w...   \n",
       "11  2018-06-05 12:45:54  @Jmg64John Hi - You could try our ID forums (h...   \n",
       "12  2018-06-05 12:45:07  @liverpoollou92 Hi - You could try our ID foru...   \n",
       "13  2018-06-05 10:33:58  #SciNews: First for the first time, scientists...   \n",
       "14  2018-06-05 08:39:28  RT @NHM_WPY: For #WorldEnvironmentDay we're re...   \n",
       "15  2018-06-04 16:08:12  Are we really made of stardust? âœ¨ Planetary sc...   \n",
       "16  2018-06-04 14:19:46  Ahead of #WorldEnvironmentDay we're sharing a ...   \n",
       "17  2018-06-04 10:56:43  #MineralMonday Taking care of the Museum's min...   \n",
       "18  2018-06-03 17:19:03  @Grantjones_ Hi Grant, try our ID forums (http...   \n",
       "19  2018-06-03 17:18:47  @yayamartin @bugmanjones Hi Jen, try our ID fo...   \n",
       "20  2018-06-03 13:56:31  RT @NHM_WPY: Did you know the Jamaican iguana ...   \n",
       "21  2018-06-02 14:23:37  Itâ€™s #ButterflyAwarenessDay. Did you know that...   \n",
       "22  2018-06-02 13:15:47  It's #ButterflyAwarenessDay ðŸ¦‹. See if you can ...   \n",
       "23  2018-06-01 13:59:24  RT @NHMdinolab: Tyrannosaur dentary in the col...   \n",
       "24  2018-06-01 11:23:09  From capturing one of the world's most endange...   \n",
       "25  2018-06-01 09:43:50  RT @OrstedUK: Continuing our celebration of #W...   \n",
       "26  2018-06-01 08:59:47  RT @NHM_WPY: The 2019 competition opens for en...   \n",
       "27  2018-06-01 08:59:38  RT @BryozoanNhm: #FossilFriday The famous Le M...   \n",
       "28  2018-05-31 14:00:45  Dippyâ€™s #Naturenauts is supported by @DellEMC,...   \n",
       "29  2018-05-31 14:00:20  Have you joined #Naturenauts? Our brand-new ap...   \n",
       "..                  ...                                                ...   \n",
       "170 2018-05-13 13:53:45  This orange butterfly can be found in the Amer...   \n",
       "171 2018-05-13 10:56:41  Human evolution expert Prof @ChrisStringer65 w...   \n",
       "172 2018-05-13 10:56:15  The Museum's @ChrisStringer65 has studied Nean...   \n",
       "173 2018-05-12 13:51:45  What's the coolest dinosaur? Swot up on your d...   \n",
       "174 2018-05-12 13:36:31  @KenWill93191945 Hi Ken - To help you identify...   \n",
       "175 2018-05-12 11:26:41  RT @anariesgogil: Nature Live @NHM_London abou...   \n",
       "176 2018-05-12 11:21:57  RT @NHM_Digitise: Happy Birthday Dippy! While ...   \n",
       "177 2018-05-12 10:45:59  RT @NHM_Visiting: We currently have a 15 minut...   \n",
       "178 2018-05-12 10:45:15  Come along to our Family Festival this May hal...   \n",
       "179 2018-05-12 09:03:54  RT @NHM_Visiting: A marine worm moves in with ...   \n",
       "180 2018-05-12 08:56:47  RT @nickcasewell: Here is a really nice short ...   \n",
       "181 2018-05-12 08:56:07  RT @NHM_London: #DippyOnTour is in partnership...   \n",
       "182 2018-05-12 08:56:00  RT @NHM_London: Dippy is getting ready for the...   \n",
       "183 2018-05-12 08:55:08  #DippyOnTour is in partnership with @GarfieldW...   \n",
       "184 2018-05-12 08:54:44  Dippy is getting ready for the next stop of hi...   \n",
       "185 2018-05-12 08:54:07  Dippy was revealed to the public #OTD in 1905 ...   \n",
       "186 2018-05-11 15:52:42  Have you ever seen a cobra spit #Venom in supe...   \n",
       "187 2018-05-11 14:37:38  RT @Filming_at_NHM: Tune in this Sunday to cat...   \n",
       "188 2018-05-11 12:55:50  RT @NHMdinolab: Returning freshly conserved fr...   \n",
       "189 2018-05-11 11:03:50  Chytridiomycosis regularly kills frogs, toads,...   \n",
       "190 2018-05-11 10:32:35  Great profile of Justin Schmidt in the Guardia...   \n",
       "191 2018-05-11 08:57:59  This weekend is your last chance to come face-...   \n",
       "192 2018-05-11 07:53:55  Life after Gollum: motion capture master Andy ...   \n",
       "193 2018-05-10 11:09:37  Meet the ancient people who rocked the surfer ...   \n",
       "194 2018-05-10 09:01:49  Rise and shine with our yoga sessions. Taking ...   \n",
       "195 2018-05-09 14:34:40  Huge congratulations to Dr Greg Edgecombe, who...   \n",
       "196 2018-05-09 13:59:15  Our live butterfly house gives you the chance ...   \n",
       "197 2018-05-09 12:52:39  RT @flygirlNHM: It's #hedgehogweek - did you k...   \n",
       "198 2018-05-09 12:01:28  RT @Shop_at_NHM: Step into the sun wearing a t...   \n",
       "199 2018-05-09 11:23:44  Monarch butterflies migrate thousands of miles...   \n",
       "\n",
       "                                              hashtags  \\\n",
       "0    [{'text': 'HoldTheWorld', 'indices': [149, 162]}]   \n",
       "1                                                   []   \n",
       "2                                                   []   \n",
       "3                                                   []   \n",
       "4                                                   []   \n",
       "5     [{'text': 'JurassicWorld', 'indices': [11, 25]}]   \n",
       "6                                                   []   \n",
       "7                                                   []   \n",
       "8      [{'text': 'JurassicWorld', 'indices': [0, 14]}]   \n",
       "9    [{'text': 'WorldEnvironmentDay', 'indices': [5...   \n",
       "10                                                  []   \n",
       "11                                                  []   \n",
       "12                                                  []   \n",
       "13            [{'text': 'SciNews', 'indices': [0, 8]}]   \n",
       "14   [{'text': 'WorldEnvironmentDay', 'indices': [1...   \n",
       "15   [{'text': 'Space', 'indices': [106, 112]}, {'t...   \n",
       "16   [{'text': 'WorldEnvironmentDay', 'indices': [9...   \n",
       "17     [{'text': 'MineralMonday', 'indices': [0, 14]}]   \n",
       "18                                                  []   \n",
       "19                                                  []   \n",
       "20     [{'text': 'WPYinsights', 'indices': [89, 101]}]   \n",
       "21   [{'text': 'ButterflyAwarenessDay', 'indices': ...   \n",
       "22   [{'text': 'ButterflyAwarenessDay', 'indices': ...   \n",
       "23                                                  []   \n",
       "24          [{'text': 'WPY53', 'indices': [164, 170]}]   \n",
       "25            [{'text': 'WPY53', 'indices': [44, 50]}]   \n",
       "26                                                  []   \n",
       "27     [{'text': 'FossilFriday', 'indices': [17, 30]}]   \n",
       "28       [{'text': 'Naturenauts', 'indices': [8, 20]}]   \n",
       "29   [{'text': 'Naturenauts', 'indices': [16, 28]},...   \n",
       "..                                                 ...   \n",
       "170  [{'text': 'SensationalButterflies', 'indices':...   \n",
       "171                                                 []   \n",
       "172                                                 []   \n",
       "173        [{'text': 'NHM_Live', 'indices': [74, 83]}]   \n",
       "174                                                 []   \n",
       "175                                                 []   \n",
       "176                                                 []   \n",
       "177                                                 []   \n",
       "178                                                 []   \n",
       "179                                                 []   \n",
       "180                                                 []   \n",
       "181     [{'text': 'DippyOnTour', 'indices': [16, 28]}]   \n",
       "182   [{'text': 'DippyOnTour', 'indices': [124, 136]}]   \n",
       "183      [{'text': 'DippyOnTour', 'indices': [0, 12]}]   \n",
       "184   [{'text': 'DippyOnTour', 'indices': [108, 120]}]   \n",
       "185             [{'text': 'OTD', 'indices': [33, 37]}]   \n",
       "186           [{'text': 'Venom', 'indices': [32, 38]}]   \n",
       "187                                                 []   \n",
       "188                                                 []   \n",
       "189                                                 []   \n",
       "190                                                 []   \n",
       "191         [{'text': 'Venom', 'indices': [103, 109]}]   \n",
       "192                                                 []   \n",
       "193  [{'text': 'Neanderthals', 'indices': [154, 167...   \n",
       "194                                                 []   \n",
       "195     [{'text': 'RSFellows', 'indices': [215, 225]}]   \n",
       "196  [{'text': 'SensationalButterflies', 'indices':...   \n",
       "197    [{'text': 'hedgehogweek', 'indices': [21, 34]}]   \n",
       "198                                                 []   \n",
       "199                                                 []   \n",
       "\n",
       "                                                  urls  \\\n",
       "0    [{'url': 'https://t.co/udPYQFhJsy', 'expanded_...   \n",
       "1    [{'url': 'https://t.co/VGOu7RrEqw', 'expanded_...   \n",
       "2    [{'url': 'https://t.co/wo0wmQFv2T', 'expanded_...   \n",
       "3                                                   []   \n",
       "4    [{'url': 'https://t.co/V0w8uV4w39', 'expanded_...   \n",
       "5    [{'url': 'https://t.co/gfJJQleucI', 'expanded_...   \n",
       "6                                                   []   \n",
       "7    [{'url': 'https://t.co/0wTWLxfVk3', 'expanded_...   \n",
       "8    [{'url': 'https://t.co/4gSgQ8roKe', 'expanded_...   \n",
       "9    [{'url': 'https://t.co/jX9sDQDuoR', 'expanded_...   \n",
       "10                                                  []   \n",
       "11   [{'url': 'https://t.co/iS3mojHHWU', 'expanded_...   \n",
       "12   [{'url': 'https://t.co/iS3mojHHWU', 'expanded_...   \n",
       "13   [{'url': 'https://t.co/UUM4NEmn5Z', 'expanded_...   \n",
       "14                                                  []   \n",
       "15   [{'url': 'https://t.co/h5hIYdBYX4', 'expanded_...   \n",
       "16   [{'url': 'https://t.co/6hHnEgbWRD', 'expanded_...   \n",
       "17   [{'url': 'https://t.co/tLFfCveEBI', 'expanded_...   \n",
       "18   [{'url': 'https://t.co/iS3mojHHWU', 'expanded_...   \n",
       "19   [{'url': 'https://t.co/iS3mojHHWU', 'expanded_...   \n",
       "20                                                  []   \n",
       "21                                                  []   \n",
       "22   [{'url': 'https://t.co/F0Ogxb7HdU', 'expanded_...   \n",
       "23                                                  []   \n",
       "24   [{'url': 'https://t.co/TOcK4Z8sfV', 'expanded_...   \n",
       "25                                                  []   \n",
       "26                                                  []   \n",
       "27                                                  []   \n",
       "28                                                  []   \n",
       "29   [{'url': 'https://t.co/FTy8uPEkXT', 'expanded_...   \n",
       "..                                                 ...   \n",
       "170  [{'url': 'https://t.co/0fZNHedhc6', 'expanded_...   \n",
       "171  [{'url': 'https://t.co/mPJCXiKEYu', 'expanded_...   \n",
       "172  [{'url': 'https://t.co/PRQt86brOz', 'expanded_...   \n",
       "173  [{'url': 'https://t.co/uFQTioRh4O', 'expanded_...   \n",
       "174  [{'url': 'https://t.co/Of82R2ZGRH', 'expanded_...   \n",
       "175                                                 []   \n",
       "176                                                 []   \n",
       "177                                                 []   \n",
       "178  [{'url': 'https://t.co/y1UzQlgtvB', 'expanded_...   \n",
       "179                                                 []   \n",
       "180                                                 []   \n",
       "181                                                 []   \n",
       "182                                                 []   \n",
       "183                                                 []   \n",
       "184  [{'url': 'https://t.co/lPE7qQq7Dw', 'expanded_...   \n",
       "185  [{'url': 'https://t.co/rk6niJ0MlM', 'expanded_...   \n",
       "186  [{'url': 'https://t.co/zvSrFuRLvX', 'expanded_...   \n",
       "187                                                 []   \n",
       "188                                                 []   \n",
       "189  [{'url': 'https://t.co/1CyeG8IknD', 'expanded_...   \n",
       "190  [{'url': 'https://t.co/8JdCXmSFr6', 'expanded_...   \n",
       "191  [{'url': 'https://t.co/fdgYCipzHQ', 'expanded_...   \n",
       "192  [{'url': 'https://t.co/PZpdaZ0iw7', 'expanded_...   \n",
       "193  [{'url': 'https://t.co/iF7Z4qbuau', 'expanded_...   \n",
       "194  [{'url': 'https://t.co/am5Fscx6g7', 'expanded_...   \n",
       "195                                                 []   \n",
       "196  [{'url': 'https://t.co/h5dpDQUt4M', 'expanded_...   \n",
       "197                                                 []   \n",
       "198  [{'url': 'https://t.co/12a9nTlCQ5', 'expanded_...   \n",
       "199  [{'url': 'https://t.co/IDFQIPCAFj', 'expanded_...   \n",
       "\n",
       "                                         user mentions       repying to  \\\n",
       "0                                                   []             None   \n",
       "1                                                   []             None   \n",
       "2    [{'screen_name': 'Tweetisaurus', 'name': 'Susi...             None   \n",
       "3    [{'screen_name': 'NHM_London', 'name': 'Natura...             None   \n",
       "4                                                   []       NHM_London   \n",
       "5    [{'screen_name': 'NHMdinolab', 'name': 'NHMdin...             None   \n",
       "6    [{'screen_name': 'NHM_London', 'name': 'Natura...             None   \n",
       "7                                                   []       NHM_London   \n",
       "8                                                   []             None   \n",
       "9                                                   []             None   \n",
       "10   [{'screen_name': 'BBCR1', 'name': 'BBC Radio 1...             None   \n",
       "11   [{'screen_name': 'Jmg64John', 'name': 'Johnoor...        Jmg64John   \n",
       "12   [{'screen_name': 'liverpoollou92', 'name': 'El...   liverpoollou92   \n",
       "13                                                  []             None   \n",
       "14   [{'screen_name': 'NHM_WPY', 'name': 'Wildlife ...             None   \n",
       "15                                                  []             None   \n",
       "16   [{'screen_name': 'NHM_WPY', 'name': 'Wildlife ...             None   \n",
       "17                                                  []             None   \n",
       "18   [{'screen_name': 'Grantjones_', 'name': 'Grant...      Grantjones_   \n",
       "19   [{'screen_name': 'yayamartin', 'name': 'Jen', ...       yayamartin   \n",
       "20   [{'screen_name': 'NHM_WPY', 'name': 'Wildlife ...             None   \n",
       "21                                                  []             None   \n",
       "22                                                  []             None   \n",
       "23   [{'screen_name': 'NHMdinolab', 'name': 'NHMdin...             None   \n",
       "24   [{'screen_name': 'NHM_WPY', 'name': 'Wildlife ...             None   \n",
       "25   [{'screen_name': 'OrstedUK', 'name': 'Ã˜rsted U...             None   \n",
       "26   [{'screen_name': 'NHM_WPY', 'name': 'Wildlife ...             None   \n",
       "27   [{'screen_name': 'BryozoanNhm', 'name': 'NHM_B...             None   \n",
       "28   [{'screen_name': 'DellEMC', 'name': 'Dell EMC'...       NHM_London   \n",
       "29                                                  []             None   \n",
       "..                                                 ...              ...   \n",
       "170                                                 []             None   \n",
       "171  [{'screen_name': 'ChrisStringer65', 'name': 'C...       NHM_London   \n",
       "172  [{'screen_name': 'ChrisStringer65', 'name': 'C...             None   \n",
       "173                                                 []             None   \n",
       "174  [{'screen_name': 'KenWill93191945', 'name': 'K...  KenWill93191945   \n",
       "175  [{'screen_name': 'anariesgogil', 'name': 'Ana ...             None   \n",
       "176  [{'screen_name': 'NHM_Digitise', 'name': 'Digi...             None   \n",
       "177  [{'screen_name': 'NHM_Visiting', 'name': 'NHM ...             None   \n",
       "178  [{'screen_name': 'Operation_Earth', 'name': 'O...             None   \n",
       "179  [{'screen_name': 'NHM_Visiting', 'name': 'NHM ...             None   \n",
       "180  [{'screen_name': 'nickcasewell', 'name': 'Dr N...             None   \n",
       "181  [{'screen_name': 'NHM_London', 'name': 'Natura...             None   \n",
       "182  [{'screen_name': 'NHM_London', 'name': 'Natura...             None   \n",
       "183  [{'screen_name': 'GarfieldWFdn', 'name': 'Garf...       NHM_London   \n",
       "184  [{'screen_name': 'BM_AG', 'name': 'Birmingham ...       NHM_London   \n",
       "185                                                 []             None   \n",
       "186  [{'screen_name': 'LSTMnews', 'name': 'LSTM', '...             None   \n",
       "187  [{'screen_name': 'Filming_at_NHM', 'name': 'Fi...             None   \n",
       "188  [{'screen_name': 'NHMdinolab', 'name': 'NHMdin...             None   \n",
       "189                                                 []             None   \n",
       "190                                                 []             None   \n",
       "191                                                 []             None   \n",
       "192                                                 []             None   \n",
       "193                                                 []             None   \n",
       "194                                                 []             None   \n",
       "195  [{'screen_name': 'royalsociety', 'name': 'The ...             None   \n",
       "196                                                 []             None   \n",
       "197  [{'screen_name': 'flygirlNHM', 'name': 'Erica ...             None   \n",
       "198  [{'screen_name': 'Shop_at_NHM', 'name': 'Shop ...             None   \n",
       "199                                                 []             None   \n",
       "\n",
       "     retweets  favourites  \n",
       "0          53         120  \n",
       "1          23          58  \n",
       "2          28          45  \n",
       "3          24           0  \n",
       "4          24          36  \n",
       "5          47          91  \n",
       "6          41           0  \n",
       "7          41          80  \n",
       "8          75         174  \n",
       "9          30          73  \n",
       "10         65           0  \n",
       "11          0           0  \n",
       "12          0           0  \n",
       "13         40          95  \n",
       "14        189           0  \n",
       "15         28          67  \n",
       "16         49         122  \n",
       "17         41         118  \n",
       "18          0           0  \n",
       "19          0           1  \n",
       "20         19           0  \n",
       "21         75         134  \n",
       "22         60         138  \n",
       "23         55           0  \n",
       "24         47         175  \n",
       "25          4           0  \n",
       "26         35           0  \n",
       "27         29           0  \n",
       "28          0           3  \n",
       "29         19          28  \n",
       "..        ...         ...  \n",
       "170        16          84  \n",
       "171        13          48  \n",
       "172        99         233  \n",
       "173        28         102  \n",
       "174         0           0  \n",
       "175         6           0  \n",
       "176         4           0  \n",
       "177         1           0  \n",
       "178         9          23  \n",
       "179         6           0  \n",
       "180        10           0  \n",
       "181         1           0  \n",
       "182         7           0  \n",
       "183         1           6  \n",
       "184         7          13  \n",
       "185        90         203  \n",
       "186        27          38  \n",
       "187        12           0  \n",
       "188        40           0  \n",
       "189        50         107  \n",
       "190        14          43  \n",
       "191        11          51  \n",
       "192        61         129  \n",
       "193        38          86  \n",
       "194        43         197  \n",
       "195        30         146  \n",
       "196        13          46  \n",
       "197        30           0  \n",
       "198         3           0  \n",
       "199        29          90  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The article URLs provided for this project.\n",
    "article_urls = ['http://www.nhm.ac.uk/discover/the-cannibals-of-goughs-cave.html','http://www.nhm.ac.uk/discover/how-we-became-human.html','http://www.nhm.ac.uk/discover/the-origin-of-our-species.html']\n",
    "\n",
    "# Note that this script will work with other articles that share the same HTML layout. Just add URLs to this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll begin by making HTTP GET requests on the article URLs and creating Beautiful Soup objects from the HTML documents for ease of navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This creates a list of BeautifulSoup objects.\n",
    "soups = [soup(requests.get(url).text, 'html.parser') for url in article_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehensions will be used regularly throughout this project as a means of applying our data munging process to all of the articles simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup's .find() function isolates the required div elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Articles are contained in a <div class=\"article--container\"> element.\n",
    "article_divs = [item.find('div',{'class':'article--container'}) for item in soups]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a list of the article titles by navigating to the &lt;h1&gt; element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article_titles = [item.find('h1').get_text() for item in article_divs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The cannibals of Gough's Cave\",\n",
       " 'How we became human',\n",
       " 'The origin of our species']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll create objects that contain the content of each article, then strip the content of its punctuation, capitalisation and stopwords. I'll also apply a process called 'stemming' to the article, which I will explain in detail later.\n",
    "\n",
    "Let's first do some preparatory work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A handy function for flattening a list of lists into a single list.\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This gives a list BS ResultSets for all articles.\n",
    "content = [item.find_all(['p','h2']) for item in article_divs]\n",
    "#h2_content = [item.find_all('h2') for item in article_divs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def content_str(ResultSet):\n",
    "    '''Takes a Beautiful Soup ResultSet and returns all of its text as a string.'''\n",
    "    string_list = [item.get_text() for item in ResultSet]\n",
    "    string_list = [string+' ' for string in string_list]\n",
    "    string = ''.join(flatten(string_list))\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to create a data frame containing every word from every article and the title of the article it came from, so that pandas' groupby function can be leveraged to give a structured data frame where the most used words get sorted to the top.\n",
    "\n",
    "With this in mind, it will be useful to have the content organised in tuples. I've opted for tuples of the form (article title, article content). This way I can keep hold of the article title, which will be useful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a (title, article) tuple for each article and stores them in a list.\n",
    "article_strings = list(zip(article_titles,[content_str(item) for item in content]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation and capitalisation removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Punctuation and capitalisation are removed so that 'Hello!' and 'hello' would be classed as the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample paragraph notice it has no punctuation'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# This is the string '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "punctuation = string.punctuation\n",
    "\n",
    "sample_paragraph = 'Sample paragraph! Notice, it has (no) punctuation.'\n",
    "\n",
    "# List the non-punctuation characters and make everything lowercase.\n",
    "no_punc = [char for char in sample_paragraph.lower() if char not in punctuation]\n",
    "\n",
    "# Join the characters again to reform the string.\n",
    "no_punc = ''.join(no_punc)\n",
    "no_punc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process will remove common words that typically only convey syntactic (grammatical) meaning. In theory, this leaves us with only those words that convey semantic meaning. These are our candidates for keywords, since they pertain to the subject of the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Crispy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A dictionary of stopwords.\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample', 'paragraph', 'notice', 'punctuation']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Let's test this on our sample_paragraph from above.\n",
    "clean_para = [word for word in no_punc.split() if word not in stopwords.words('english')]\n",
    "clean_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the words 'it', 'has' and 'no' have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will apply the removal of punctuation and stopwords to a string.\n",
    "def text_stripper(string):\n",
    "    '''Takes a string and removes punctuation, capitalisation and stopwords.'''\n",
    "    no_punc = [char for char in string.lower() if char not in punctuation]\n",
    "    no_punc = ''.join(no_punc)\n",
    "    return [word for word in no_punc.split() if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to turn the tuples containing our content into pandas DataFrames. The next function creates a list of such DataFrames, with each entry containing a paragraph's word, its parent article and its html p tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_creator(content_tuple):\n",
    "    '''Create a pd.DataFrame for non-stopwords present in the corpus.'''\n",
    "    df_list = [pd.DataFrame(data={'Word': text_stripper(item[1]), 'Article':item[0], 'Dummy': ''}, columns=['Word','Article','Dummy']) for item in content_tuple]\n",
    "    df = pd.concat(df_list).reset_index().drop('index', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = df_creator(article_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This combines words from the same linguistic stem, so that plurals, suffixations or conjugations of the same word get counted together. Thus 'human' and 'humans' will be counted as the same keyword and so will 'cannibal', 'cannibals' and 'cannibalism'.\n",
    "\n",
    "Our stemmed results will occasionally be incorrect (for example, 'cannibal' gets stemmed to 'cannib' because -al is a common suffix). But since we're retaining the information about where our stemmed words come from, this won't be a problem. Over-stemming like this still groups words together correctly and we can simply choose our keyword to be the most common version of the stem in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Snowball Stemmer seems to strip suffixes a bit more aggressively than some other stemmers, but it also deals with more suffixes than most, so I've chosen to use this stemmer.\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human\n",
      "human\n",
      "cannib\n",
      "cannib\n",
      "cannib\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem('human'))\n",
    "print(stemmer.stem('humans'))\n",
    "print(stemmer.stem('cannibal'))\n",
    "print(stemmer.stem('cannibals'))\n",
    "print(stemmer.stem('cannibalism'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now stem our words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A simple function for us to use in pandas' .apply() method.\n",
    "def stem_func(word):\n",
    "    '''Stems a word'''\n",
    "    return stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus['Stem'] = corpus['Word'].apply(stem_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Article</th>\n",
       "      <th>Dummy</th>\n",
       "      <th>Stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Word, Article, Dummy, Stem]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[corpus['Stem'] == 'cannibal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following few cells use pandas' .groupby() method to take our corpus of words and group them by, respectively, 'Article', 'Stem' and 'Word', giving an aggregated count of the number of occurences of each stem in each article. The 20 most frequent stems will be the basis of our keywords for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Stem</th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>ancient</td>\n",
       "      <td>ancient</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>year</td>\n",
       "      <td>years</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>homo</td>\n",
       "      <td>homo</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>relat</td>\n",
       "      <td>relatives</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>ago</td>\n",
       "      <td>ago</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>around</td>\n",
       "      <td>around</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>galleri</td>\n",
       "      <td>gallery</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>visitor</td>\n",
       "      <td>visitors</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>africa</td>\n",
       "      <td>africa</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>human</td>\n",
       "      <td>humans</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>speci</td>\n",
       "      <td>species</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>fossil</td>\n",
       "      <td>fossil</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>live</td>\n",
       "      <td>lived</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>modern</td>\n",
       "      <td>modern</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>skull</td>\n",
       "      <td>skull</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>found</td>\n",
       "      <td>found</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>neanderth</td>\n",
       "      <td>neanderthal</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>scientist</td>\n",
       "      <td>scientists</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>The origin of our species</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>cave</td>\n",
       "      <td>cave</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>gough</td>\n",
       "      <td>goughs</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>bone</td>\n",
       "      <td>bone</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>silvia</td>\n",
       "      <td>silvia</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>cannib</td>\n",
       "      <td>cannibalism</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>bone</td>\n",
       "      <td>bones</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>year</td>\n",
       "      <td>years</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>evid</td>\n",
       "      <td>evidence</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>mark</td>\n",
       "      <td>marks</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>may</td>\n",
       "      <td>may</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>museum</td>\n",
       "      <td>museum</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>peopl</td>\n",
       "      <td>people</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>skull</td>\n",
       "      <td>skulls</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>ago</td>\n",
       "      <td>ago</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>magdalenian</td>\n",
       "      <td>magdalenians</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>say</td>\n",
       "      <td>says</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>analysi</td>\n",
       "      <td>analysis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>engrav</td>\n",
       "      <td>engraved</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>The cannibals of Gough's Cave</td>\n",
       "      <td>engrav</td>\n",
       "      <td>engraving</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>homo</td>\n",
       "      <td>homo</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>year</td>\n",
       "      <td>years</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>size</td>\n",
       "      <td>size</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>ago</td>\n",
       "      <td>ago</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>brain</td>\n",
       "      <td>brains</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>human</td>\n",
       "      <td>humans</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>million</td>\n",
       "      <td>million</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>grip</td>\n",
       "      <td>grip</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>larger</td>\n",
       "      <td>larger</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>male</td>\n",
       "      <td>males</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>much</td>\n",
       "      <td>much</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>tool</td>\n",
       "      <td>tools</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>around</td>\n",
       "      <td>around</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>australopithecus</td>\n",
       "      <td>australopithecus</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>brain</td>\n",
       "      <td>brain</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>chang</td>\n",
       "      <td>changes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>childhood</td>\n",
       "      <td>childhood</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Article              Stem              Word  Count\n",
       "1079      The origin of our species             human             human     20\n",
       "875       The origin of our species           ancient           ancient     17\n",
       "1319      The origin of our species              year             years     17\n",
       "1078      The origin of our species              homo              homo     16\n",
       "1201      The origin of our species             relat         relatives     14\n",
       "868       The origin of our species               ago               ago     12\n",
       "882       The origin of our species            around            around     12\n",
       "1048      The origin of our species           galleri           gallery     12\n",
       "1306      The origin of our species           visitor          visitors     11\n",
       "867       The origin of our species            africa            africa     10\n",
       "1080      The origin of our species             human            humans     10\n",
       "1251      The origin of our species             speci           species      9\n",
       "1043      The origin of our species            fossil            fossil      7\n",
       "1123      The origin of our species              live             lived      7\n",
       "1141      The origin of our species            modern            modern      7\n",
       "1244      The origin of our species             skull             skull      7\n",
       "1045      The origin of our species             found             found      6\n",
       "1146      The origin of our species         neanderth       neanderthal      6\n",
       "1224      The origin of our species         scientist        scientists      6\n",
       "1300      The origin of our species                us                us      6\n",
       "497   The cannibals of Gough's Cave              cave              cave     19\n",
       "618   The cannibals of Gough's Cave             human             human     18\n",
       "602   The cannibals of Gough's Cave             gough            goughs     14\n",
       "472   The cannibals of Gough's Cave              bone              bone     11\n",
       "766   The cannibals of Gough's Cave            silvia            silvia     10\n",
       "489   The cannibals of Gough's Cave            cannib       cannibalism      8\n",
       "473   The cannibals of Gough's Cave              bone             bones      7\n",
       "837   The cannibals of Gough's Cave              year             years      7\n",
       "570   The cannibals of Gough's Cave              evid          evidence      6\n",
       "664   The cannibals of Gough's Cave              mark             marks      6\n",
       "667   The cannibals of Gough's Cave               may               may      6\n",
       "679   The cannibals of Gough's Cave            museum            museum      6\n",
       "704   The cannibals of Gough's Cave             peopl            people      6\n",
       "775   The cannibals of Gough's Cave             skull            skulls      6\n",
       "439   The cannibals of Gough's Cave               ago               ago      5\n",
       "657   The cannibals of Gough's Cave       magdalenian      magdalenians      5\n",
       "747   The cannibals of Gough's Cave               say              says      5\n",
       "443   The cannibals of Gough's Cave           analysi          analysis      4\n",
       "566   The cannibals of Gough's Cave            engrav          engraved      4\n",
       "567   The cannibals of Gough's Cave            engrav         engraving      4\n",
       "188             How we became human             human             human     13\n",
       "186             How we became human              homo              homo      9\n",
       "401             How we became human                us                us      8\n",
       "419             How we became human              year             years      8\n",
       "341             How we became human              size              size      7\n",
       "18              How we became human               ago               ago      6\n",
       "59              How we became human             brain            brains      6\n",
       "189             How we became human             human            humans      6\n",
       "247             How we became human           million           million      6\n",
       "177             How we became human              grip              grip      5\n",
       "214             How we became human            larger            larger      5\n",
       "238             How we became human              male             males      5\n",
       "251             How we became human              much              much      5\n",
       "377             How we became human              time              time      5\n",
       "384             How we became human              tool             tools      5\n",
       "37              How we became human            around            around      4\n",
       "41              How we became human  australopithecus  australopithecus      4\n",
       "58              How we became human             brain             brain      4\n",
       "74              How we became human             chang           changes      4\n",
       "77              How we became human         childhood         childhood      4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The main groupby function.\n",
    "keywords = corpus.groupby(['Article','Stem','Word']).count()\n",
    "\n",
    "# Sorting values by descending frequency and cutting away all but the top 20.\n",
    "keywords = keywords.reset_index().sort_values(['Article','Dummy'], ascending=False).groupby('Article').head(20)\n",
    "keywords.rename(columns={'Dummy':'Count'}, inplace=True)\n",
    "keywords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might wish to view a data frame of keywords for each article, one at a time, so here I've written a function to split our 'groupby' dataframe back into individual article DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_article_keywords(article_title):    \n",
    "    keyword_table = keywords[keywords['Article'] == article_title]\n",
    "    return keyword_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a subscriptable list of keyword dataframes.\n",
    "article_keywords = [generate_article_keywords(item) for item in article_titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if you wish to see keywords for a particular article, you can either call generate_article_keywords('Article Title') or subscript article_keywords[i] to the i<sup>th</sup> article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Stem</th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>homo</td>\n",
       "      <td>homo</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>year</td>\n",
       "      <td>years</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>size</td>\n",
       "      <td>size</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>ago</td>\n",
       "      <td>ago</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>brain</td>\n",
       "      <td>brains</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>human</td>\n",
       "      <td>humans</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>million</td>\n",
       "      <td>million</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>grip</td>\n",
       "      <td>grip</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>larger</td>\n",
       "      <td>larger</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>male</td>\n",
       "      <td>males</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>much</td>\n",
       "      <td>much</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>tool</td>\n",
       "      <td>tools</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>around</td>\n",
       "      <td>around</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>australopithecus</td>\n",
       "      <td>australopithecus</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>brain</td>\n",
       "      <td>brain</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>chang</td>\n",
       "      <td>changes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>childhood</td>\n",
       "      <td>childhood</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Article              Stem              Word  Count\n",
       "188  How we became human             human             human     13\n",
       "186  How we became human              homo              homo      9\n",
       "401  How we became human                us                us      8\n",
       "419  How we became human              year             years      8\n",
       "341  How we became human              size              size      7\n",
       "18   How we became human               ago               ago      6\n",
       "59   How we became human             brain            brains      6\n",
       "189  How we became human             human            humans      6\n",
       "247  How we became human           million           million      6\n",
       "177  How we became human              grip              grip      5\n",
       "214  How we became human            larger            larger      5\n",
       "238  How we became human              male             males      5\n",
       "251  How we became human              much              much      5\n",
       "377  How we became human              time              time      5\n",
       "384  How we became human              tool             tools      5\n",
       "37   How we became human            around            around      4\n",
       "41   How we became human  australopithecus  australopithecus      4\n",
       "58   How we became human             brain             brain      4\n",
       "74   How we became human             chang           changes      4\n",
       "77   How we became human         childhood         childhood      4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_keywords[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Stem</th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>homo</td>\n",
       "      <td>homo</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>year</td>\n",
       "      <td>years</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>size</td>\n",
       "      <td>size</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>ago</td>\n",
       "      <td>ago</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>brain</td>\n",
       "      <td>brains</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>human</td>\n",
       "      <td>humans</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>million</td>\n",
       "      <td>million</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>grip</td>\n",
       "      <td>grip</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>larger</td>\n",
       "      <td>larger</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>male</td>\n",
       "      <td>males</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>much</td>\n",
       "      <td>much</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>tool</td>\n",
       "      <td>tools</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>around</td>\n",
       "      <td>around</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>australopithecus</td>\n",
       "      <td>australopithecus</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>brain</td>\n",
       "      <td>brain</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>chang</td>\n",
       "      <td>changes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>How we became human</td>\n",
       "      <td>childhood</td>\n",
       "      <td>childhood</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Article              Stem              Word  Count\n",
       "188  How we became human             human             human     13\n",
       "186  How we became human              homo              homo      9\n",
       "401  How we became human                us                us      8\n",
       "419  How we became human              year             years      8\n",
       "341  How we became human              size              size      7\n",
       "18   How we became human               ago               ago      6\n",
       "59   How we became human             brain            brains      6\n",
       "189  How we became human             human            humans      6\n",
       "247  How we became human           million           million      6\n",
       "177  How we became human              grip              grip      5\n",
       "214  How we became human            larger            larger      5\n",
       "238  How we became human              male             males      5\n",
       "251  How we became human              much              much      5\n",
       "377  How we became human              time              time      5\n",
       "384  How we became human              tool             tools      5\n",
       "37   How we became human            around            around      4\n",
       "41   How we became human  australopithecus  australopithecus      4\n",
       "58   How we became human             brain             brain      4\n",
       "74   How we became human             chang           changes      4\n",
       "77   How we became human         childhood         childhood      4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_article_keywords('How we became human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
